{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG SIGNAL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author :** Ravi Narayana K S\n",
    "\n",
    "**Date :** 03.07.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPLEMENTATION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importing Dependencies :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, DepthwiseConv2D, SeparableConv2D, AveragePooling2D, Flatten, Dense, Dropout, Activation, Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Loading Data :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Loading file names :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data' # folder containing the data\n",
    "edf_files_1 = sorted([file for file in os.listdir(data_folder) if file.endswith('_1.edf')]) # rest\n",
    "edf_files_2 = sorted([file for file in os.listdir(data_folder) if file.endswith('_2.edf')]) # task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Loading raw(.edf) files :*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*raws1* and *raws2* contain the raw files of class 1 and class 2 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raws1 = [] # rest\n",
    "for edf_file in edf_files_1:\n",
    "    raw = mne.io.read_raw_edf(os.path.join(data_folder, edf_file), preload=True)\n",
    "    raws1.append(raw)\n",
    "\n",
    "raws2 = [] # task\n",
    "for edf_file in edf_files_2:\n",
    "    raw = mne.io.read_raw_edf(os.path.join(data_folder, edf_file), preload=True)\n",
    "    raws2.append(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualising the loaded data :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raws1[0].info)\n",
    "plt.close()\n",
    "raws1[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raws2[0].info)\n",
    "plt.close()\n",
    "raws2[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculate PSD :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*rawPSDs1* and *rawPSDs2* contain the PSDs of raw files of class 1 and class 2 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawPSDs1 = [] # rest\n",
    "for raw in raws1:\n",
    "    rawPSD = raw.compute_psd(fmin=0, fmax=100, n_fft=2048)\n",
    "    rawPSDs1.append(rawPSD)\n",
    "\n",
    "rawPSDs2 = [] # task\n",
    "for raw in raws2:\n",
    "    rawPSD = raw.compute_psd(fmin=0, fmax=100, n_fft=2048)\n",
    "    rawPSDs2.append(rawPSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualising PSD for class 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawPSDs1[0].info)\n",
    "plt.close()\n",
    "rawPSDs1[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualising PSD for class 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rawPSDs2[0].info)\n",
    "plt.close()\n",
    "rawPSDs2[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We observe high fluctuation in the data belonging to class 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Defining Bands :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {'Delta': (1, 4), 'Theta': (4, 8), 'Alpha': (8, 12), 'Beta': (12, 30), 'Gamma': (30, 100)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating bandwise PSD :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSDs1 = []\n",
    "Freqs1 = []\n",
    "\n",
    "for rawPSD in rawPSDs1:\n",
    "    PSD, Freq = rawPSD.get_data(return_freqs=True)  \n",
    "    PSDs1.append(PSD)\n",
    "    Freqs1.append(Freq)\n",
    "\n",
    "PSDs2 = []\n",
    "Freqs2 = []\n",
    "\n",
    "for rawPSD in rawPSDs2:\n",
    "    PSD, Freq = rawPSD.get_data(return_freqs=True)  \n",
    "    PSDs2.append(PSD)\n",
    "    Freqs2.append(Freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*bandPSDs1* and *bandPSDs2* contain the bandwise PSDs of raw files of class 1 and class 2 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandPSDs1 = [] # rest\n",
    "for i in range(len(PSDs1)):\n",
    "    psds = PSDs1[i]\n",
    "    freqs = Freqs1[i]\n",
    "    band_psd = {band:[] for band in bands}\n",
    "\n",
    "    for band, (fmin,fmax) in bands.items():\n",
    "        idx = np.logical_and(freqs>=fmin,freqs<=fmax)\n",
    "        band_psd[band] = np.mean(psds[:,idx],axis=1)\n",
    "\n",
    "    bandPSDs1.append(band_psd)\n",
    "\n",
    "bandPSDs2 = [] # task\n",
    "for i in range(len(PSDs2)):\n",
    "    psds = PSDs2[i]\n",
    "    freqs = Freqs2[i]\n",
    "    band_psd = {band:[] for band in bands}\n",
    "\n",
    "    for band, (fmin,fmax) in bands.items():\n",
    "        idx = np.logical_and(freqs>=fmin,freqs<=fmax)\n",
    "        band_psd[band] = np.mean(psds[:,idx],axis=1)\n",
    "\n",
    "    bandPSDs2.append(band_psd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculating the difference :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIFFs = []\n",
    "\n",
    "for i in range(len(bandPSDs1)):\n",
    "    DIFF = {band:[] for band in bands}\n",
    "    for band in bands:\n",
    "        diff = bandPSDs1[i][band] - bandPSDs2[i][band]\n",
    "        DIFF[band].append(diff)\n",
    "    DIFFs.append(DIFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualising the difference :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "for j in range(len(DIFFs)):\n",
    "    for i,band in enumerate(bands):\n",
    "        plt.plot(np.abs(DIFFs[j][band][0]),label=f'{band}')\n",
    "    plt.title(f'Difference in Band PSD ({band},{j}) : Rest-Task')\n",
    "    plt.xlabel('channels')\n",
    "    plt.ylabel('PSD Difference (db/Hz)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We observe that **ALPHA, THETA and DELTA** bands are sensitive to change of state from rest to task*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "for band in bands:\n",
    "    for i,j in enumerate(range(len(DIFFs))):\n",
    "        plt.plot(np.abs(DIFFs[j][band][0]),label=f'{band}')\n",
    "    plt.title(f'Difference in Band PSD ({band}) : Rest-Task')\n",
    "    plt.xlabel('channels')\n",
    "    plt.ylabel('PSD Difference (db/Hz)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We observe that*\n",
    "* **ALPHA** band signal fluctuation occurs in channels between ~7-20\n",
    "* **THETA** band signal fluctuation occurs in channels between ~5-8 and ~15-20\n",
    "* **DELTA** band signal fluctuation occurs in channel 15\n",
    "* **GAMMA** band signal fluctuation occurs in channels between ~2-18\n",
    "\n",
    "\n",
    "* 21st Channel shows high fluctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating dataset for model training :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in PSDs1:\n",
    "    data.append(i)\n",
    "    labels.append(0)\n",
    "\n",
    "for i in PSDs2:\n",
    "    data.append(i)\n",
    "    labels.append(1)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42,shuffle=True)\n",
    "\n",
    "# Reshape data\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implementing EEGNET :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5, kernLength = 64, F1 = 8, D = 2, F2 = 16, norm_rate = 0.25):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(F1, (1, kernLength), padding = 'same', input_shape = (Chans, Samples, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DepthwiseConv2D((Chans, 1), padding = 'valid', depth_multiplier = D))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(AveragePooling2D((1, 4)))\n",
    "    model.add(Dropout(dropoutRate))\n",
    "    model.add(SeparableConv2D(F2, (1, 16), padding = 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(AveragePooling2D((1, 8)))\n",
    "    model.add(Dropout(dropoutRate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(nb_classes, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_EEGNET = EEGNet(nb_classes=2, Chans=X_train.shape[1], Samples=410)\n",
    "model_EEGNET.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_EEGNET.fit(X_train, y_train, batch_size=16, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating models :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_EEGNET.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model_EEGNET.predict(X_test)\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "print(y_hat == y_test,'\\n')\n",
    "\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "prec = precision_score(y_test, y_hat)\n",
    "rec = recall_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat)\n",
    "con = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "print(f'Accuracy: {acc}\\nPrecision: {prec}\\nRecall: {rec}\\nF1: {f1}\\nConfusion Matrix: \\n{con}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implementing TSCeption :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Model Builders :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSCeptionBlock(input_tensor, filters, kernel_sizes):\n",
    "    convs = []\n",
    "    for kernel_size in kernel_sizes:\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=(1, kernel_size), padding='same', activation='relu')(input_tensor)\n",
    "        conv = layers.BatchNormalization()(conv)\n",
    "        convs.append(conv)\n",
    "    output = layers.Concatenate(axis=-1)(convs)\n",
    "    return output\n",
    "\n",
    "def TSCeptionModel(input_shape, num_classes, num_blocks=3, filters=16, kernel_sizes=[3, 5, 7]):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    x = input_layer\n",
    "    for _ in range(num_blocks):\n",
    "        x = TSCeptionBlock(x, filters, kernel_sizes)\n",
    "        x = layers.MaxPooling2D(pool_size=(1, 2))(x)\n",
    "        filters *= 2\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (21, 410, 1)  #(channels, sample, 1)\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling Model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TSC = TSCeptionModel(input_shape, num_classes)\n",
    "model_TSC.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_TSC.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_TSC.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating Model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TSC.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model_TSC.predict(X_test)\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "print(y_hat == y_test,'\\n')\n",
    "\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "prec = precision_score(y_test, y_hat)\n",
    "rec = recall_score(y_test, y_hat)\n",
    "f1 = f1_score(y_test, y_hat)\n",
    "con = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "print(f'Accuracy: {acc}\\nPrecision: {prec}\\nRecall: {rec}\\nF1: {f1}\\nConfusion Matrix: \\n{con}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating Processed Dataset for classification :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range(len(bandPSDs1)):\n",
    "    row = []\n",
    "    for band in bands:\n",
    "        for j in bandPSDs1[i][band]:\n",
    "            row.append(j)\n",
    "    row.append(0)\n",
    "    dataset.append(row)\n",
    "\n",
    "for i in range(len(bandPSDs2)):\n",
    "    row = []\n",
    "    for band in bands:\n",
    "        for j in bandPSDs2[i][band]:\n",
    "            row.append(j)\n",
    "    row.append(1)\n",
    "    dataset.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "dataset.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spliting dataset into training and testing batches :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:-1]\n",
    "Y = dataset[:,-1].astype(int)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implementing Convolution model :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Reshape((21,5,1), input_shape=(105,)))\n",
    "model.add(Conv2D(16, (5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(4, (5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling Model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, batch_size=32, epochs=250, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysing training vs validation curves for accuacy and loss :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating model :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "print(y_hat == Y_test,'\\n')\n",
    "\n",
    "acc = accuracy_score(Y_test, y_hat)\n",
    "prec = precision_score(Y_test, y_hat)\n",
    "rec = recall_score(Y_test, y_hat)\n",
    "f1 = f1_score(Y_test, y_hat)\n",
    "con = confusion_matrix(Y_test, y_hat)\n",
    "\n",
    "print(f'Accuracy: {acc}\\nPrecision: {prec}\\nRecall: {rec}\\nF1: {f1}\\nConfusion Matrix: \\n{con}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. With Respect to Data\n",
    "\n",
    "    * Upon analysing the PSD trends of two classes, it is observed that the PSD curve of class 2 (task) is noisy.\n",
    "\n",
    "    * Upon analysing the bandwise PSD and comparing bandwise PSDs of two classes, we observe that the ALPHA, THETA and DELTA bands fluctuate more than other bands.\n",
    "\n",
    "    * The above inference brings up to conclusion that these bands are sensitive to change of state (0 -> 1).\n",
    "\n",
    "    * Analysing the visualisations of difference between the bandwise PSDs we observe lot of fluctuations in data of 21st channel.\n",
    "\n",
    "2. With Respect to Models Trained\n",
    "\n",
    "    * The EEGNET model trains well in short span of time with training accuracy up to 65% and validation accuracy of about 45%.\n",
    "\n",
    "    * The TSCeption model also performs similarly.\n",
    "\n",
    "    * The much simplar CNN used gives output simliar to the previous models.\n",
    "\n",
    "    * both the models are observed to have given the same scores,\n",
    "\n",
    "    accuracy_score = 0.333333\n",
    "    precision_score = 0.333333\n",
    "    f1_score = 0.5\n",
    "    confusion_matrix = [[0 , 10],\n",
    "                        [0 , 5 ]]\n",
    "\n",
    "3. With Respect to Model Evaluation\n",
    "\n",
    "    * Upon close inspection of model traing history, we observe that the models are overfitting and hence doesnt generalise properly.\n",
    "\n",
    "    * This can be inferred by looking at training_acc >> validation_acc and testing_acc << groungTruth.\n",
    "\n",
    "    * Regularisation used did indeed reduce bit of overfitting, but overfitting does persist. Thus the overfitting can be removed only by increasing number of records in data.\n",
    "\n",
    "4. With Respect to Experimentation\n",
    "\n",
    "    * Upon exploring cleaning and reordering the PSD for eeg signal, the processed dataset consists of each record of shape (21,410,1).\n",
    "\n",
    "    * A simple CNN trained on this dataset performs as good as models discussed earliercwith same sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iitR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
